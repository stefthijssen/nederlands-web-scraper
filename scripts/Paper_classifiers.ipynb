{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_f = open('../data/nl.json')\n",
    "en_f = open('../data/en.json')\n",
    "nl_data = json.load(nl_f)\n",
    "en_data = json.load(en_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_tokenized = []\n",
    "excluded_keywords = ['www', 'index', 'html', 'htm', 'html', 'http', 'https']\n",
    "nl_tlds = ['.nl/', '.be/', '.su/', '.aw/', '.sx/', '.cw/']\n",
    "other_tlds = ['.com/', '.net/', '.org/']\n",
    "\n",
    "for element in nl_data[0:5000]:\n",
    "    url_element = element['siteUrl'] + ('' if element['siteUrl'].endswith('/') else '/')\n",
    "    split = [word for word in re.split('[^a-zA-Z]', url_element) \n",
    "        if len(word) >= 2 and word not in excluded_keywords]\n",
    "    split_sentence = ' '.join(split)\n",
    "    custom_feat =[\n",
    "        1 if any(tld in url_element for tld in nl_tlds) else 0,\n",
    "        1 if any(tld in url_element for tld in other_tlds) else 0\n",
    "    ]\n",
    "    urls_tokenized.append([split_sentence, custom_feat, url_element, 1])\n",
    "\n",
    "for element in en_data[0:5000]:\n",
    "    url_element = element['siteUrl'] + ('' if element['siteUrl'].endswith('/') else '/')\n",
    "    split = [word for word in re.split('[^a-zA-Z]', url_element) \n",
    "        if len(word) >= 2 and word not in excluded_keywords]\n",
    "    split_sentence = ' '.join(split)\n",
    "    custom_feat =[\n",
    "        1 if any(tld in url_element for tld in nl_tlds) else 0,\n",
    "        1 if any(tld in url_element for tld in other_tlds) else 0\n",
    "    ]\n",
    "    urls_tokenized.append([split_sentence, custom_feat, url_element, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tevansleen nl', [1, 0], 'https://www.tevansleen.nl/', 1]\n"
     ]
    }
   ],
   "source": [
    "print(urls_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: NOT NECESSARY SINCE TRAIN_TEST_SPLIT ALREADY SHUFFLES VALUES\n",
    "\n",
    "#Train Test split - ONLY RUN ONCE AFTER INITIALIZATION\n",
    "# random.shuffle(urls_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tevansleen nl 1\n",
      "  (0, 10558)\t1\n",
      "  (0, 7549)\t1\n",
      "  (1, 7549)\t1\n",
      "  (1, 2194)\t1\n",
      "  (2, 7549)\t1\n",
      "  (2, 5052)\t1\n",
      "  (3, 7549)\t1\n",
      "  (3, 12101)\t1\n",
      "  (3, 9710)\t1\n",
      "  (4, 7549)\t1\n",
      "  (4, 10274)\t1\n",
      "  (5, 7549)\t1\n",
      "  (5, 10851)\t1\n",
      "  (6, 7549)\t1\n",
      "  (6, 10551)\t1\n",
      "  (7, 894)\t1\n",
      "  (7, 2193)\t1\n",
      "  (8, 7549)\t1\n",
      "  (8, 1420)\t1\n",
      "  (9, 2193)\t1\n",
      "  (9, 9813)\t1\n",
      "  (10, 7549)\t1\n",
      "  (10, 9998)\t1\n",
      "  (10, 5152)\t1\n",
      "  (10, 4762)\t1\n",
      "  :\t:\n",
      "  (9992, 963)\t1\n",
      "  (9993, 2193)\t1\n",
      "  (9993, 8362)\t1\n",
      "  (9993, 11885)\t1\n",
      "  (9994, 2193)\t1\n",
      "  (9994, 433)\t1\n",
      "  (9994, 7781)\t1\n",
      "  (9994, 2603)\t1\n",
      "  (9995, 2193)\t1\n",
      "  (9995, 1314)\t1\n",
      "  (9995, 784)\t1\n",
      "  (9996, 2193)\t1\n",
      "  (9996, 10912)\t1\n",
      "  (9996, 5642)\t1\n",
      "  (9996, 5641)\t1\n",
      "  (9997, 2193)\t2\n",
      "  (9997, 3033)\t1\n",
      "  (9997, 5013)\t1\n",
      "  (9997, 8589)\t1\n",
      "  (9997, 1875)\t1\n",
      "  (9997, 9281)\t1\n",
      "  (9998, 3961)\t1\n",
      "  (9998, 8426)\t1\n",
      "  (9999, 2193)\t1\n",
      "  (9999, 12273)\t1\n"
     ]
    }
   ],
   "source": [
    "X_tokens, X_url, y = [], [], []\n",
    "for url in urls_tokenized:\n",
    "    X_tokens.append(url[0])\n",
    "    X_url.append(url[2])\n",
    "    y.append(url[3])\n",
    "\n",
    "print(X_tokens[0], y[0])\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_tokens = vectorizer.fit_transform(X_tokens)\n",
    "\n",
    "print(X_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actcult\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names_out()[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_token_train, X_token_test, y_token_train, y_token_test = train_test_split(X_tokens, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "# ccTLD - no training necessary because it just looks at TLD:\n",
    "ccTLD_y = []\n",
    "for url in X_url:\n",
    "    ccTLD_y.append(1 if any(tld in url for tld in nl_tlds) else 0)\n",
    "\n",
    "print(len(ccTLD_y))\n",
    "\n",
    "# ccTLD+ Would give the same outcome as TLD in our case because it counts generic TLD's (.com/.net/.org) as non-dutch anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2612)\t1\n",
      "  (0, 3963)\t1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(X_token_train[0])\n",
    "print(y_token_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token features\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_token_train.toarray(), y_token_train).predict(X_token_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4924,   76],\n",
       "       [ 840, 4160]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, ccTLD_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[532, 485],\n",
       "       [ 26, 957]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_token_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without numeric characters: \n",
    "array([[ 94, 106],\n",
    "       [  3, 197]])\n",
    "\n",
    "With numeric characters:\n",
    "array([[ 88, 108],\n",
    "       [  2, 202]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
