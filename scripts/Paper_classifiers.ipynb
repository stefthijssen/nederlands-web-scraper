{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_f = open('../data/nl.json')\n",
    "en_f = open('../data/en.json')\n",
    "nl_data = json.load(nl_f)\n",
    "en_data = json.load(en_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_tokenized = []\n",
    "excluded_keywords = ['www', 'index', 'html', 'htm', 'html', 'http', 'https']\n",
    "nl_tlds = ['.nl/', '.be/', '.su/', '.aw/', '.sx/', '.cw/']\n",
    "other_tlds = ['.com/', '.net/', '.org/']\n",
    "\n",
    "for element in nl_data:\n",
    "    url_element = element['siteUrl'] + ('' if element['siteUrl'].endswith('/') else '/')\n",
    "    split = [word for word in re.split('[^a-zA-Z]', url_element) \n",
    "        if len(word) >= 2 and word not in excluded_keywords]\n",
    "    custom_feat =[\n",
    "        1 if any(tld in url_element for tld in nl_tlds) else 0,\n",
    "        1 if any(tld in url_element for tld in other_tlds) else 0\n",
    "    ]\n",
    "    urls_tokenized.append([split, custom_feat, url_element, 1])\n",
    "\n",
    "for element in en_data:\n",
    "    url_element = element['siteUrl'] + ('' if element['siteUrl'].endswith('/') else '/')\n",
    "    split = [word for word in re.split('[^a-zA-Z]', url_element) \n",
    "        if len(word) >= 2 and word not in excluded_keywords]\n",
    "    custom_feat =[\n",
    "        1 if any(tld in url_element for tld in nl_tlds) else 0,\n",
    "        1 if any(tld in url_element for tld in other_tlds) else 0\n",
    "    ]\n",
    "    urls_tokenized.append([split, custom_feat, url_element, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['tevansleen', 'nl'], [1, 0], 'https://www.tevansleen.nl/', 1]\n"
     ]
    }
   ],
   "source": [
    "print(urls_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: NOT NECESSARY SINCE TRAIN_TEST_SPLIT ALREADY SHUFFLES VALUES\n",
    "\n",
    "#Train Test split - ONLY RUN ONCE AFTER INITIALIZATION\n",
    "# random.shuffle(urls_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tevansleen', 'nl'] 1\n",
      "  (0, 48496)\t1\n",
      "  (0, 113266)\t1\n",
      "  (0, 97817)\t1\n",
      "  (0, 70871)\t1\n",
      "  (1, 113266)\t1\n",
      "  (1, 70871)\t1\n",
      "  (1, 48494)\t1\n",
      "  (1, 24724)\t1\n",
      "  (2, 48496)\t1\n",
      "  (2, 70871)\t1\n",
      "  (2, 49062)\t1\n",
      "  (3, 48496)\t1\n",
      "  (3, 113266)\t1\n",
      "  (3, 70871)\t1\n",
      "  (3, 111964)\t1\n",
      "  (3, 90715)\t1\n",
      "  (4, 48496)\t1\n",
      "  (4, 113266)\t1\n",
      "  (4, 70871)\t1\n",
      "  (4, 95156)\t1\n",
      "  (5, 48496)\t1\n",
      "  (5, 113266)\t1\n",
      "  (5, 70871)\t1\n",
      "  (5, 100724)\t1\n",
      "  (6, 48496)\t1\n",
      "  :\t:\n",
      "  (108457, 48494)\t1\n",
      "  (108457, 102419)\t1\n",
      "  (108457, 108915)\t1\n",
      "  (108458, 48496)\t1\n",
      "  (108458, 113266)\t1\n",
      "  (108458, 74432)\t1\n",
      "  (108458, 104923)\t1\n",
      "  (108459, 48496)\t1\n",
      "  (108459, 24700)\t1\n",
      "  (108459, 47512)\t1\n",
      "  (108459, 90435)\t1\n",
      "  (108459, 90465)\t1\n",
      "  (108459, 42812)\t1\n",
      "  (108459, 101399)\t1\n",
      "  (108460, 113266)\t1\n",
      "  (108460, 48494)\t1\n",
      "  (108460, 24700)\t1\n",
      "  (108460, 23514)\t1\n",
      "  (108460, 87127)\t1\n",
      "  (108460, 100176)\t1\n",
      "  (108460, 43455)\t1\n",
      "  (108461, 48496)\t1\n",
      "  (108461, 113266)\t1\n",
      "  (108461, 24700)\t1\n",
      "  (108461, 54059)\t1\n"
     ]
    }
   ],
   "source": [
    "X_tokens, X_url, y = [], [], []\n",
    "for url in urls_tokenized:\n",
    "    X_tokens.append(url[0])\n",
    "    X_url.append(url[2])\n",
    "    y.append(url[3])\n",
    "\n",
    "print(X_tokens[0], y[0])\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_tokens = vectorizer.fit_transform(X_url)\n",
    "\n",
    "print(X_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primhome\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names_out()[80000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_token_train, X_token_test, y_token_train, y_token_test = train_test_split(X_tokens, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108462\n"
     ]
    }
   ],
   "source": [
    "# ccTLD - no training necessary because it just looks at TLD:\n",
    "ccTLD_y = []\n",
    "for url in X_url:\n",
    "    ccTLD_y.append(1 if any(tld in url for tld in nl_tlds) else 0)\n",
    "\n",
    "print(len(ccTLD_y))\n",
    "\n",
    "# ccTLD+ Would give the same outcome as TLD in our case because it counts generic TLD's (.com/.net/.org) as non-dutch anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 48496)\t1\n",
      "  (0, 113266)\t1\n",
      "  (0, 48468)\t1\n",
      "  (0, 74432)\t1\n",
      "  (0, 3537)\t1\n",
      "  (0, 31195)\t1\n",
      "  (0, 51312)\t1\n",
      "  (0, 79482)\t1\n",
      "  (0, 21699)\t1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(X_token_train[0])\n",
    "print(y_token_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token features\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_token_train.toarray(), y_token_train).predict(X_token_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y, ccTLD_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at S.executeCodeCell (/Users/bonoijpelaar/.vscode/extensions/ms-toolsai.jupyter-2021.10.1101450599/out/client/extension.js:66:301742)",
      "at S.execute (/Users/bonoijpelaar/.vscode/extensions/ms-toolsai.jupyter-2021.10.1101450599/out/client/extension.js:66:300732)",
      "at S.start (/Users/bonoijpelaar/.vscode/extensions/ms-toolsai.jupyter-2021.10.1101450599/out/client/extension.js:66:296408)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/Users/bonoijpelaar/.vscode/extensions/ms-toolsai.jupyter-2021.10.1101450599/out/client/extension.js:66:312326)",
      "at async t.CellExecutionQueue.start (/Users/bonoijpelaar/.vscode/extensions/ms-toolsai.jupyter-2021.10.1101450599/out/client/extension.js:66:311862)"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at S.executeCodeCell (/Users/bonoijpelaar/.vscode/extensions/ms-toolsai.jupyter-2021.10.1101450599/out/client/extension.js:66:301742)",
      "at S.execute (/Users/bonoijpelaar/.vscode/extensions/ms-toolsai.jupyter-2021.10.1101450599/out/client/extension.js:66:300732)",
      "at S.start (/Users/bonoijpelaar/.vscode/extensions/ms-toolsai.jupyter-2021.10.1101450599/out/client/extension.js:66:296408)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/Users/bonoijpelaar/.vscode/extensions/ms-toolsai.jupyter-2021.10.1101450599/out/client/extension.js:66:312326)",
      "at async t.CellExecutionQueue.start (/Users/bonoijpelaar/.vscode/extensions/ms-toolsai.jupyter-2021.10.1101450599/out/client/extension.js:66:311862)"
     ]
    }
   ],
   "source": [
    "confusion_matrix(y_token_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
